<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" version="2.0"><channel><title>Big Yang Theory</title><description>Math, Code, &amp; Everything in Between</description><link>http://localhost:2368/</link><generator>Ghost 0.7</generator><lastBuildDate>Sun, 06 Dec 2015 19:33:49 GMT</lastBuildDate><atom:link href="http://localhost:2368/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title>Least Squares Regression &amp; The Fundamental Theorem of Linear Algebra</title><description>&lt;p&gt;I know I said I was going to write another post on the Rubik's cube, but I don't feel like making helper videos at the moment, so instead I'm going to write about another subject I love a lot - Least Squares Regression and its connection to the Fundamental Theorem&lt;/p&gt;</description><link>http://localhost:2368/from-least-squares-regression-to-the-fundamental-theorem-of-linear-algebra/</link><guid isPermaLink="false">d7f75e7e-c203-4b11-a136-5790e8dffad6</guid><dc:creator>Jeffrey Yang</dc:creator><pubDate>Sun, 29 Nov 2015 04:30:01 GMT</pubDate><content:encoded>&lt;p&gt;I know I said I was going to write another post on the Rubik's cube, but I don't feel like making helper videos at the moment, so instead I'm going to write about another subject I love a lot - Least Squares Regression and its connection to the Fundamental Theorem of Linear Algebra.  Least Squares Regression, more generally referred to as Regression Analysis, is ultimately the process by which all algorithms for assessing relationships between variables is based on.  Maybe the word 'correlation' may help.  Least Squares Regression gives us a method by which we can quantify and estimate the magnitude of the correlation between two variables.&lt;/p&gt;

&lt;p&gt;I apologize for the jargon, perhaps an example will alleviate the situation.  Let's say you decided to start you're own business making, say, home-brew beer.  You are doing it on the side as you already have a stable job.  You're side business starts to grow much faster than you imagined.  You think to yourself, maybe you could quit your current job - which you weren't exactly infatuated with, but it paid the bills - and work on this beer business full-time.  But how do you quantify whether or not this a realistic endeavor?  How do you judge whether or not this business can make you enough to sustain your mode of living?&lt;/p&gt;

&lt;p&gt;Enter Least Squares Regression - the foundation which all forecasting and correlation algorithms are based upon.  If you've ever used Excel to try to quantify and predict a future outcome, you've used least squares regression.  I will stop here in terms of explaining least squares regression's applicability (there are enumerable articles on that - just google), instead I will elaborate on the mathematics behind how it's performed - simply because it can be done (primarily) in one of two ways, the naive way requires calculus, the elegant way requires only algebra - linear algebra (and in fact, this is how computers do it).  The fact that I could solve a problem with only algebra, but which I naively assumed required calculus, has always - and will always astound me - and I hope to share that with you today.&lt;/p&gt;

&lt;p&gt;Example of Linear Least Squares &lt;br&gt;
&lt;img src="https://upload.wikimedia.org/wikipedia/commons/3/3a/Linear_regression.svg" alt="least_squares"&gt; &lt;br&gt;
&lt;span style="font-size:14px"&gt;[&lt;span style="font-style:italic"&gt;taken from wikipedia&lt;/span&gt;]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;  &lt;/p&gt;

&lt;h2&gt;Calculus&lt;/h2&gt;

&lt;p&gt;I will first begin with the more straightforward method, which, ironically is arguably the harder way to find a correlation function as it requires calculus. Say you are given a set of data points: &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;(x&lt;sub&gt;1&lt;/sub&gt;,y&lt;sub&gt;1&lt;/sub&gt;), (x&lt;sub&gt;2&lt;/sub&gt;,y&lt;sub&gt;2&lt;/sub&gt;), ...(x&lt;sub&gt;n&lt;/sub&gt;,y&lt;sub&gt;n&lt;/sub&gt;)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Going back to our previous example, the x value could represent a week or a month, and the y value represents the respective sales on your home-brewed beer.  For simplicities sake, we will use just three points:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;(1, $100), (2, $200), (3, $350)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;That is, on week 1 you made a $100 profit, on week 2 you made $200, and week 3 you made $350.&lt;/p&gt;

&lt;p&gt;Plotting this on a Cartesian coordinate graph, you notice that the points seem to align - that is, it is possible there is a correlation between the two variables - in this case, the time and the respective sales during that time.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2015/11/Screen-Shot-2015-11-18-at-6-13-31-PM.png" alt=""&gt;&lt;/p&gt;

&lt;p&gt;If you could quantify this relationship, then you'd have a very good way of forecasting your sales at a future point in time assuming you continue to grow your beer business.  So how do we go about this?  Think back to your elementary algebra and geometry days.  Again, for simplicities sake, I've chosen three points such that they roughly lie on a straight line.  Recall, the equation for a line in the Cartesian coordinate system:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;f(x) = y = mx + b&lt;/strong&gt; &lt;br&gt;
&lt;strong&gt;y&lt;/strong&gt; is equal to a function of &lt;strong&gt;x&lt;/strong&gt;, a.k.a. &lt;strong&gt;f(x)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I know it's ugly and you probably hated it when you were forced to learn it, but just bear with me, I hope to make it better by the end of this post.  Here we have our general equation for a straight line - &lt;strong&gt;m&lt;/strong&gt; is the &lt;strong&gt;slope&lt;/strong&gt; of the line, and &lt;strong&gt;b&lt;/strong&gt; is its &lt;strong&gt;y-intercept&lt;/strong&gt;.  We want to find the function &lt;strong&gt;f(x)&lt;/strong&gt; such that the sum of the squared residuals is minimized, that is:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;S = (y&lt;sub&gt;1&lt;/sub&gt; - f(x&lt;sub&gt;1&lt;/sub&gt;))&lt;sup&gt;2&lt;/sup&gt; + (y&lt;sub&gt;2&lt;/sub&gt; - f(x&lt;sub&gt;2&lt;/sub&gt;))&lt;sup&gt;2&lt;/sup&gt; + ... + (y&lt;sub&gt;n&lt;/sub&gt; - f(x&lt;sub&gt;n&lt;/sub&gt;))&lt;sup&gt;2&lt;/sup&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Why do we have to square the residuals?  Well the points could lie either above or below the best fit line, but what we care about is minimizing the magnitude of the deviation, so we square the residual so negative and positive residuals are treated equally.  &lt;/p&gt;

&lt;p&gt;Now, how do we minimize this sum of the squared residuals?  Well if you remember from calculus (for those of you who've never taken calculus you can skip ahead if you'd like) we take the derivative of the summation 'function' with respect to our 'unknowns' and set it equal to zero.  Then, solve that equation for our 'unknown'.&lt;/p&gt;

&lt;p&gt;&lt;font size="3"&gt;&amp;delta;&lt;/font&gt;&lt;strong&gt;&lt;font size="4"&gt;S&lt;/font&gt;&lt;/strong&gt; &amp;frasl; &lt;font size="3"&gt;&amp;delta;&lt;/font&gt;&lt;strong&gt;&lt;font size="4"&gt;(unknown)&lt;/font&gt;&lt;/strong&gt; = 0 &lt;br&gt;
[&lt;font size="3"&gt;&amp;delta;&lt;/font&gt; here is the partial differential operator]&lt;/p&gt;

&lt;p&gt;Well what are our unknowns in this case?  We are given our &lt;strong&gt;x&lt;/strong&gt; values and &lt;strong&gt;y&lt;/strong&gt; values from our data points, so our unknowns are actually &lt;strong&gt;m&lt;/strong&gt; and &lt;strong&gt;b&lt;/strong&gt;, the coefficients to our equation! That is, our unknowns are the slope of the line and the y-intercept of the line we want to solve for - as we should expect.  To be clear our sum function is actually a function of &lt;strong&gt;m&lt;/strong&gt; and &lt;strong&gt;b&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;S(m,b) &amp;nbsp;=&amp;nbsp; r&lt;sub&gt;1&lt;/sub&gt;(m,b) + r&lt;sub&gt;2&lt;/sub&gt;(m,b) + ... + r&lt;sub&gt;n&lt;/sub&gt;(m,b)&lt;/strong&gt; &lt;br&gt;
where &lt;strong&gt;r&lt;sub&gt;n&lt;/sub&gt;(m,b) &amp;nbsp;=&amp;nbsp; (y&lt;sub&gt;n&lt;/sub&gt; - f(x&lt;sub&gt;n&lt;/sub&gt;))&lt;sup&gt;2&lt;/sup&gt; &amp;nbsp;=&amp;nbsp; (y&lt;sub&gt;n&lt;/sub&gt; - (m x&lt;sub&gt;n&lt;/sub&gt; + b))&lt;sup&gt;2&lt;/sup&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;in our specific example with the points &lt;strong&gt;(1, $100), (2, $200), (3, $350)&lt;/strong&gt; our &lt;strong&gt;S(m,b)&lt;/strong&gt; would be (dropping the dollar signs):&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;S(m,b) &amp;nbsp;=&amp;nbsp; (100 - (m + b))&lt;sup&gt;2&lt;/sup&gt; + (200 - (2m + b))&lt;sup&gt;2&lt;/sup&gt; + (350 - (3m + b))&lt;sup&gt;2&lt;/sup&gt; &lt;br&gt;
&lt;/strong&gt;or&lt;strong&gt; &lt;br&gt;
S(m,b) &amp;nbsp;=&amp;nbsp; 172500 - 3100m - 1300b + 12mb + 14m&lt;sup&gt;2&lt;/sup&gt; + 3b&lt;sup&gt;2&lt;/sup&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Now, because in this case our sum function &lt;strong&gt;S&lt;/strong&gt; is a function of two variables, in order to be solved for we will need two equations.  Remember a system of equations is only solvable if the number of variables to be solved for is equal to the number of unique equations given.  In this case we will take the partial derivative of &lt;strong&gt;S&lt;/strong&gt;, once with &lt;strong&gt;m&lt;/strong&gt;, and once with &lt;strong&gt;b&lt;/strong&gt; - and set each equal to zero.  This gives us our two equations to be solved given our two unknowns &lt;strong&gt;m&lt;/strong&gt; and &lt;strong&gt;b&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;font size="3"&gt;&amp;delta;&lt;/font&gt;&lt;strong&gt;&lt;font size="4"&gt;S&lt;/font&gt;&lt;/strong&gt; &amp;frasl; &lt;font size="3"&gt;&amp;delta;&lt;/font&gt;&lt;strong&gt;&lt;font size="4"&gt;m&lt;/font&gt; &amp;nbsp;=&amp;nbsp; -3100 + 28m + 12b &amp;nbsp;=&amp;nbsp; 0&lt;/strong&gt; &lt;br&gt;
&lt;font size="3"&gt;&amp;delta;&lt;/font&gt;&lt;strong&gt;&lt;font size="4"&gt;S&lt;/font&gt;&lt;/strong&gt; &amp;frasl; &lt;font size="3"&gt;&amp;delta;&lt;/font&gt;&lt;strong&gt;&lt;font size="4"&gt;b&lt;/font&gt; &amp;nbsp;=&amp;nbsp; -1300 + 6b + 12m &amp;nbsp;=&amp;nbsp; 0&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;where &lt;font size="3"&gt;&amp;delta;&lt;/font&gt;&lt;strong&gt;&lt;font size="4"&gt;S&lt;/font&gt;&lt;/strong&gt; &amp;frasl; &lt;font size="3"&gt;&amp;delta;&lt;/font&gt;&lt;strong&gt;&lt;font size="4"&gt;m&lt;/font&gt;&lt;/strong&gt; is the partial derivative of &lt;strong&gt;S&lt;/strong&gt; with respect to &lt;strong&gt;m&lt;/strong&gt; and &lt;font size="3"&gt;&amp;delta;&lt;/font&gt;&lt;strong&gt;&lt;font size="4"&gt;S&lt;/font&gt;&lt;/strong&gt; &amp;frasl; &lt;font size="3"&gt;&amp;delta;&lt;/font&gt;&lt;strong&gt;&lt;font size="4"&gt;b&lt;/font&gt;&lt;/strong&gt; is the partial derivative of &lt;strong&gt;S&lt;/strong&gt; with respect to &lt;strong&gt;b&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Solving for this we get &lt;strong&gt;m = 125&lt;/strong&gt; , &lt;strong&gt;b = -33.33...&lt;/strong&gt; &lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2015/11/Screen-Shot-2015-11-21-at-7-00-55-AM.png" alt=""&gt;
&lt;br&gt;  &lt;/p&gt;

&lt;h2&gt;Linear Algebra&lt;/h2&gt;

&lt;p&gt;Whew!  That was the naive, yet hard way to find the correlation.  Now I present to you the more abstract, but more visual and conceptual method by which to view the problem.  This, in fact, is the method which your computer solves for the correlation - this is exactly how Excel finds that best fit function given the input set of points.  This approach is an inherent consequence of the Fundamental Theorem of Linear Algebra and is very intimately connected with the properties of spaces (vector spaces) in general.&lt;/p&gt;

&lt;p&gt;Completely abstracting from what was done earlier, we now re-write our problem in linear algebra form:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;font size="5" style="text-decoration:overline"&gt;X&lt;/font&gt; &lt;font style="text-decoration:overline"&gt;c&lt;/font&gt; = &lt;font style="text-decoration:overline"&gt;y&lt;/font&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2015/11/Screen-Shot-2015-11-19-at-1-41-50-AM.png" alt=""&gt;&lt;/p&gt;

&lt;p&gt;where &lt;strong&gt;&lt;font size="5" style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;/strong&gt; is a matrix and &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;c&lt;/font&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;y&lt;/font&gt;&lt;/strong&gt; are column vectors. &lt;br&gt;
&lt;span style="font-size:14px"&gt;[&lt;span style="font-style:italic"&gt;the matrix &lt;font style="text-decoration:overline"&gt;X&lt;/font&gt; here is specific for finding a polynomial or order one (that is a straight line) and has 3 rows because we have 3 points, similarly for the vector &lt;font style="text-decoration:overline"&gt;y&lt;/font&gt;&lt;/span&gt;]&lt;/span&gt; &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;font size="5" style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;/strong&gt; is the matrix made up of the input &lt;strong&gt;x&lt;sub&gt;n&lt;/sub&gt;&lt;/strong&gt; values in an arrangement specific to a particular function space (explained later...), and the &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;c&lt;/font&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;y&lt;/font&gt;&lt;/strong&gt; vectors are made up of the unknown coefficients &lt;strong&gt;c&lt;sub&gt;n&lt;/sub&gt;&lt;/strong&gt; and input &lt;strong&gt;y&lt;sub&gt;n&lt;/sub&gt;&lt;/strong&gt; values, respectively.&lt;/p&gt;

&lt;p&gt;that is, &lt;/p&gt;

&lt;p&gt;substituting our values for &lt;strong&gt;x&lt;sub&gt;n&lt;/sub&gt;&lt;/strong&gt; and &lt;strong&gt;y&lt;sub&gt;n&lt;/sub&gt;&lt;/strong&gt; and replacing our coefficients &lt;strong&gt;c&lt;sub&gt;0&lt;/sub&gt;&lt;/strong&gt; and &lt;strong&gt;c&lt;sub&gt;1&lt;/sub&gt;&lt;/strong&gt; with the familiar &lt;strong&gt;b&lt;/strong&gt; and &lt;strong&gt;m&lt;/strong&gt;, respectively, we get:&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2015/11/Screen-Shot-2015-11-19-at-1-44-58-AM.png" alt=""&gt;&lt;/p&gt;

&lt;p&gt;Notice we place our given &lt;strong&gt;x&lt;sub&gt;n&lt;/sub&gt;&lt;/strong&gt; values into a matrix, our unknown constants in a column vector to be multiplied with the matrix &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;/strong&gt;, and our given &lt;strong&gt;y&lt;sub&gt;n&lt;/sub&gt;&lt;/strong&gt; values in a column vector on the other side.  If we carry out the matrix multiplication shown, we'd end up with three equations &lt;strong&gt;y&lt;sub&gt;n&lt;/sub&gt; = b + m x&lt;sub&gt;n&lt;/sub&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;y&lt;sub&gt;1&lt;/sub&gt; &amp;nbsp;=&amp;nbsp; b + m x&lt;sub&gt;1&lt;/sub&gt; &amp;nbsp;=&amp;nbsp; b + &amp;nbsp;&amp;nbsp;m &amp;nbsp;=&amp;nbsp; $100&lt;/strong&gt; &lt;br&gt;
&lt;strong&gt;y&lt;sub&gt;2&lt;/sub&gt; &amp;nbsp;=&amp;nbsp; b + m x&lt;sub&gt;2&lt;/sub&gt; &amp;nbsp;=&amp;nbsp; b + 2m &amp;nbsp;=&amp;nbsp; $200&lt;/strong&gt; &lt;br&gt;
&lt;strong&gt;y&lt;sub&gt;3&lt;/sub&gt; &amp;nbsp;=&amp;nbsp; b + m x&lt;sub&gt;3&lt;/sub&gt; &amp;nbsp;=&amp;nbsp; b + 3m &amp;nbsp;=&amp;nbsp; $350&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Notice how these three equations are the just our equation for the line with the three respective points substituted.  And now for the heart of the trick (I love using this line).  I will quickly - and without any explanation - demonstrate the linear algebra operations performed to solve for the column vector that contains the unknown coefficients (below is the generalized case for solving for the best fit polynomial of the &lt;strong&gt;n&lt;/strong&gt;th degree).&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2015/11/Screen-Shot-2015-11-28-at-7-35-39-PM.png" alt=""&gt;
or in our case, &lt;br&gt;
&lt;img src="http://localhost:2368/content/images/2015/11/Screen-Shot-2015-11-27-at-3-24-43-AM.png" alt=""&gt;&lt;/p&gt;

&lt;p&gt;so &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;strong&gt;b = -33.333...&lt;/strong&gt; &lt;br&gt;
and &lt;strong&gt;m = 125&lt;/strong&gt; as before.&lt;/p&gt;

&lt;p&gt;And with that we have solved for our unknown coefficients - crazy isn't it?  For those who have an understanding of what is going on, we have gone from using calculus to using purely algebra - linear algebra - to find our correlation function.  We have, quite literally, went from needing to take derivatives, to just multiplying, adding, and subtracting in a specific order, and our outcome is the same as before.  So, this begs the question, why does this work?&lt;/p&gt;

&lt;p&gt;Our original matrix &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;/strong&gt; can be thought of as a linear map (think something like the underscore map function, for those of you in my cohort) between the space of coefficients &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;c&lt;/font&gt;&lt;/strong&gt; (our unknowns, in this case &lt;strong&gt;b&lt;/strong&gt; and &lt;strong&gt;m&lt;/strong&gt;) to the space of &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;y&lt;/font&gt;&lt;/strong&gt; values.  The reverse map, that is &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;sup&gt;T&lt;/sup&gt;&lt;/strong&gt;, the transpose of &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;/strong&gt;, maps from the space of &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;y&lt;/font&gt;&lt;/strong&gt; values to the space of coefficient values &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;c&lt;/font&gt;&lt;/strong&gt;, in our case &lt;strong&gt;b&lt;/strong&gt; and &lt;strong&gt;m&lt;/strong&gt;. (refer to diagram below)&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2015/11/least-squares_rank-nullity_diagram.png" alt=""&gt;
&lt;span style="font-size:14px"&gt;[&lt;span style="font-style:italic"&gt;I spent way too long making this image than I'd like to admit...&lt;/span&gt;]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;What is conceptually happening here is that, because we only have a limited set of &lt;strong&gt;x&lt;/strong&gt; values that make up our matrix &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;/strong&gt;, we can not expect to be able to encompass the entire space of &lt;strong&gt;y&lt;/strong&gt; values.  So our general &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;y&lt;/font&gt;&lt;/strong&gt; vector well have one part residing within the space of &lt;strong&gt;y&lt;/strong&gt; values that can be mapped to by &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;/strong&gt;  (referred to above as the image space of &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;/strong&gt; or &lt;strong&gt;im(&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;)&lt;/strong&gt;), but it will also have an orthogonal component that the map &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;/strong&gt; knows nothing about.  Hence, the reverse mapping of &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;/strong&gt;, that is &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;sup&gt;T&lt;/sup&gt;&lt;/strong&gt;, cannot know anything about this orthogonal component as well.  So when we map the &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;y&lt;/font&gt;&lt;/strong&gt; vector back to the space of coefficient values, the component of the &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;y&lt;/font&gt;&lt;/strong&gt; vector that is orthogonal to the image space of &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;/strong&gt; is effectively mapped to &lt;strong&gt;0&lt;/strong&gt; by the reverse map &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;sup&gt;T&lt;/sup&gt;&lt;/strong&gt; - we say that the orthogonal component resides within the kernel space of &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;sup&gt;T&lt;/sup&gt;&lt;/strong&gt; or &lt;strong&gt;ker(&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;sup&gt;T&lt;/sup&gt;)&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;[this is a less visual, but more explicit diagram - this statement is denoted the Fundamental Theorem of Linear Algebra]&lt;/p&gt;

&lt;p&gt;&lt;img src="http://localhost:2368/content/images/2015/11/The_four_subspaces-X-1.svg" alt=""&gt;
&lt;span style="font-size:14px"&gt;[&lt;span style="font-style:italic"&gt;taken from wikipedia - changed A to X to match my notation&lt;/span&gt;]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;These are the four fundamental subspaces of a linear map and their symmetric relationships to one another: each map is really two maps mapping in opposite directions, one of which we denote the transpose of the other (in our case &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;sup&gt;T&lt;/sup&gt;&lt;/strong&gt;). Kernel spaces are mapped to &lt;strong&gt;0&lt;/strong&gt; and &lt;strong&gt;0&lt;/strong&gt; is a unique point in a vector space.&lt;/p&gt;

&lt;p&gt;The heart of the trick really is the multiplication of the equation via &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;sup&gt;T&lt;/sup&gt;&lt;/strong&gt; - that the incomplete knowledge of the original map &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;/strong&gt; allows us to use its backwards map as a method of finding the best approximation via the given input information (recall that the given information, the &lt;strong&gt;x&lt;/strong&gt; values, determine the map &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;/strong&gt;).  After that, we merely perform standard algebraic operations to solve for the vector of our coefficients via &lt;strong&gt;&lt;font style="text-decoration:overline"&gt;c&lt;/font&gt;&amp;nbsp;=&amp;nbsp;(&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;sup&gt;T&lt;/sup&gt;&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;)&lt;sup&gt;-1&lt;/sup&gt;&lt;font style="text-decoration:overline"&gt;X&lt;/font&gt;&lt;sup&gt;T&lt;/sup&gt;&lt;font style="text-decoration:overline"&gt;y&lt;/font&gt;&lt;/strong&gt;.  This concept really had me dumbfounded when I first understood it, and it continues to perplex me to this day. Before then, I had only known how to solve for the correlation function via calculus and to realize I could do the same with merely addition, subtraction, and multiplication in a specific order was astonishing for me to realize. &lt;/p&gt;

&lt;p&gt;In this example I've only demonstrated how to find the best fit straight line that fits the data in question.  However, it is quite a natural extension to extrapolate these same principles and find the best polynomial curve of any order less than the number of data points that are unique in their inputs (the &lt;strong&gt;x&lt;/strong&gt; values).  Abstracting further, you can find the best fit exponential, trigonometric, or logarithmic curve - in fact, you can find the best fit of any type of function from what's called a function space - so long as they are 'complete' (this usage of the word may be slightly off, but what I mean by complete is if you had all infinite orders of said functions, they can span the entire space being mapped to).&lt;/p&gt;

&lt;p&gt;Unfortunately, it appears this post has become too lengthy, so I will postpone the astonishing abstractions for a future post.  Again, if you've made it this far, congratulations.  I hope there was at least some semblance of coherent logic that you were able to follow.  I've made a web application you can clone at &lt;a href="https://github.com/jeffycyang/least-squares-calculator"&gt;https://github.com/jeffycyang/least-squares-calculator&lt;/a&gt; that will return the best fit polynomial of any order of your choosing given a set of data you input.  It's incomplete at the moment, so you're welcome to contribute if you'd like.  As always, stay happy, stay passionate, stay strong - and take care of yourselves.&lt;/p&gt;</content:encoded></item><item><title>Rubik's Cube &amp; Abstract Algebra</title><description>&lt;p&gt;My goal today is, hopefully, to have you understand a method by which you can solve the Rubik's Cube (and in fact, any one of what they call 'twisty puzzles' - so long as they are not 'deep cut') intuitively, without the need to memorize algorithms.  The Rubik's Cube behaves&lt;/p&gt;</description><link>http://localhost:2368/rubiks-cube-abstract-algebra/</link><guid isPermaLink="false">892d3f11-5034-4119-808e-403b02903d3a</guid><dc:creator>Jeffrey Yang</dc:creator><pubDate>Sun, 01 Nov 2015 12:17:56 GMT</pubDate><content:encoded>&lt;p&gt;My goal today is, hopefully, to have you understand a method by which you can solve the Rubik's Cube (and in fact, any one of what they call 'twisty puzzles' - so long as they are not 'deep cut') intuitively, without the need to memorize algorithms.  The Rubik's Cube behaves in a predictable manner which can be characterized, mathematically, as a form of algebra - abstract algebra.  Ideally, it'd be best if you had a Rubik's Cube in your hand, but even if you don't, I am convinced you will still be able to see the logic and come to realize that it really isn't hard at all (mostly just muscle memory).&lt;/p&gt;

&lt;p&gt;Before diving in, I want to point out an aside on abstract algebra so the jargon will not be as daunting - which it really isn't.  Specifically, I will be talking about the commutative property in algebra.  Given two numbers, for example 2 and 5, we say addition is commutative because 2 + 5 = 5 + 2.  That is, we can swap the variables in our operation and the outcome is the same.  Similarly, multiplication is commutative, 2 &amp;#215; 5 = 5 &amp;#215; 2.  Now this is not necessarily true - there are algebraic operations that aren't commutative, such as division (I leave that to you to think about).&lt;/p&gt;

&lt;p&gt;The same concept applies in abstract algebra - we no longer assume operations are inherently commutative.  In abstract algebra, there is a property of an algebraic operation called a Commutator which gives an "indication of the extent to which a [binary] operation fails to be commutative".  The Commutator of two elements in an algebra, say, Q and P is [Q,P] = Q &lt;strong&gt;&amp;middot;&lt;/strong&gt; P &lt;strong&gt;&amp;middot;&lt;/strong&gt; Q&lt;sup&gt;-1&lt;/sup&gt; &lt;strong&gt;&amp;middot;&lt;/strong&gt; P&lt;sup&gt;-1&lt;/sup&gt; where &lt;strong&gt;&amp;middot;&lt;/strong&gt; denotes the operation concerned (not necessarily multiplication) and raising to the negative one power means the associated inverse of the element under that operation.  For example, in standard algebra under the operation of addition with the elements 2 and 5 we would have [2,5] = 2 + 5 + (-2) + (-5) = 0.  Or with multiplication we have [2,5] = 2 &amp;#215; 5 &amp;#215; (&amp;frac12;) &amp;#215; (&amp;frac15;) = 1.&lt;/p&gt;

&lt;p&gt;Notice how, because addition and multiplication are commutative, the value of the commutator is equal to the Identity element associated with the operation.  That is, the Identity element for addition is 0 and the identity element for multiplication is 1.  The Identity element of an operation is the element for which when the operation is carried out between that element and any other element, will return the other element unchanged - so Q + 0 = Q, and Q &amp;#215; 1 = Q.  In abstract algebra, specifically in the case of non-commutative operations, the commutator will most likely not be equal to the associated Identity element.  And it is this deviation from the Identity element that indicates the extent to which the operation fails to be commutative.&lt;/p&gt;

&lt;p&gt;In the case of the Rubik's Cube, our elements are no longer numbers, they are physical manipulations on the cube - say, rotating a face clockwise.  And, in fact, they could be any number of manipulations concatenated together - which we refer to as an 'algorithm'.  Let's take a look at one algorithm now.&lt;/p&gt;

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/TViLqiRc43g" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;Notice what this algorithm does, it flips one corner clockwise and another corner counterclockwise.  Now let us dissect what is happening in the language of abstract algebra, specifically, that of commutators.  I am going to break this algorithm up into four pieces - Q, P, Q&lt;sup&gt;-1&lt;/sup&gt;, P&lt;sup&gt;-1&lt;/sup&gt;.  This is exactly the commutator I've been referring to, I will be performing [Q,P] = Q &lt;strong&gt;&amp;middot;&lt;/strong&gt; P &lt;strong&gt;&amp;middot;&lt;/strong&gt; Q&lt;sup&gt;-1&lt;/sup&gt; &lt;strong&gt;&amp;middot;&lt;/strong&gt; P&lt;sup&gt;-1&lt;/sup&gt;.  Let me first demonstrate Q and its inverse Q&lt;sup&gt;-1&lt;/sup&gt;.&lt;/p&gt;

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/qvxFF7IXH6U" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;What does Q do?  Pay close attention to the video.  Q rotates a corner clockwise and leaves the rest of that top face unchanged.  However, it completely screws up the bottom two layers.  So, what happens when I perform Q&lt;sup&gt;-1&lt;/sup&gt;?  Well, it's going to rotate that same corner on the top face back counterclockwise - fixing it's orientation - AND it's going to completely fix the bottom two layers as well, leaving us back with a solved cube.  Let's see that again.&lt;/p&gt;

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/qvxFF7IXH6U" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;Notice how performing Q and then its inverse Q&lt;sup&gt;-1&lt;/sup&gt; right after, we are returned the solved cube as we should expect.  Why?  Because an inverse by definition will invert what was done irregardless of the whether or not an operation is commutative - that is the definition of an inverse.  So Q &lt;strong&gt;&amp;middot;&lt;/strong&gt; Q&lt;sup&gt;-1&lt;/sup&gt; will always be the Identity element - nothing is changed (Q &lt;strong&gt;&amp;middot;&lt;/strong&gt; Q&lt;sup&gt;-1&lt;/sup&gt; = Identity).&lt;/p&gt;

&lt;p&gt;Similarly, let me now show you P and its inverse P&lt;sup&gt;-1&lt;/sup&gt;.&lt;/p&gt;

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/29WQbEOd5nM" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;Hilariously short right? I'm just turning a face and then turning it back.&lt;/p&gt;

&lt;p&gt;Now comes the heart of the trick, I will now perform the commutator [Q,P] = Q &lt;strong&gt;&amp;middot;&lt;/strong&gt; P &lt;strong&gt;&amp;middot;&lt;/strong&gt; Q&lt;sup&gt;-1&lt;/sup&gt; &lt;strong&gt;&amp;middot;&lt;/strong&gt; P&lt;sup&gt;-1&lt;/sup&gt;.&lt;/p&gt;

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/7yYZnrEFHIY" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;What happened?  I just created the first algorithm I showed you!  ORIENTATION MATTERS when performing manipulations.  By performing P in between Q and Q&lt;sup&gt;-1&lt;/sup&gt;, I am replacing the spot wherein the corner will be rotated counterclockwise in Q&lt;sup&gt;-1&lt;/sup&gt;.  Had I not performed P - that is rotating the top face - I would've just performed Q &lt;strong&gt;&amp;middot;&lt;/strong&gt; Q&lt;sup&gt;-1&lt;/sup&gt; and be reverted back to the solved cube.  After performing Q &lt;strong&gt;&amp;middot;&lt;/strong&gt; P &lt;strong&gt;&amp;middot;&lt;/strong&gt; Q&lt;sup&gt;-1&lt;/sup&gt;, I've essentially rotated one corner clockwise and another counterclockwise.  And performing P&lt;sup&gt;-1&lt;/sup&gt; just brings the top layer back to its original orientation.  One more time.&lt;/p&gt;

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/VMqa2LEXcIM" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;Notice that this commutator is not the Identity because we are not returned a solved cube.  But also notice, we've only made a very small change to the solved cube - that is we rotated one corner clockwise and another corner counterclockwise.  If Rubik's cube manipulations were commutative, we would expect a solved cube after performing the commutator, but because the operation of Rubik's cube manipulations are not commutative, we instead get a 'small' deviation from the Identity element - a measure of the extent to which Rubik's cube manipulations fail to be commutative (not exactly pertinent information, just interesting).&lt;/p&gt;

&lt;p&gt;This went waaayyy longer than I expected - for that, I apologize.  Once again, if you've made it this far, thank you for reading, I truly appreciate it.  I hope it was as fun of a read for you as it was for me to write.  I will make a second part in the coming week (or two) to give you 3 more commutators with which you can solve the entire Rubik's cube.  And with practice, you will learn to make your own and be able to solve any non-deep-cut twisty puzzles.  As always - stay happy, stay strong, stay passionate, and take care of yourselves.&lt;/p&gt;</content:encoded></item><item><title>Uncertainty &amp; Approximation - Physical &amp; Ephemeral</title><description>&lt;p&gt;No man has ever drawn a perfect circle, no metal beam ever made has been perfectly straight - no point drawn has ever been zero dimensional, and no sphere ever truly spherical.  We strive for predictability and determinism, yet we live in a reality that is inherently uncertain and indeterminate.&lt;/p&gt;</description><link>http://localhost:2368/uncertainty-approximation-physical-ephemeral/</link><guid isPermaLink="false">80d4ffd3-b143-4051-b8cb-8c26671ac185</guid><dc:creator>Jeffrey Yang</dc:creator><pubDate>Thu, 22 Oct 2015 04:24:29 GMT</pubDate><content:encoded>&lt;p&gt;No man has ever drawn a perfect circle, no metal beam ever made has been perfectly straight - no point drawn has ever been zero dimensional, and no sphere ever truly spherical.  We strive for predictability and determinism, yet we live in a reality that is inherently uncertain and indeterminate.  If there is a message in this post, which there may or may be not, it would be that the only certainty - is that there will always be uncertainty.&lt;/p&gt;

&lt;p&gt;99.999...% of all problems ever encountered in the physical sciences (in fact, in any discipline) are not exactly solvable.  We are raised in an environment within which infinite precision is impossible, yet we are led to believe it is attainable. Unless you were educated in an accelerated or advanced high school program, you've probably never truly internalized this concept until attending college level quantitative science courses (I know I didn't).&lt;/p&gt;

&lt;p&gt;In this current context, I am specifically referring to the inability to solve for a variable(s) in your equation exactly.  Take, for example, calculating the necessary curvature for an airplane wing to achieve a certain amount of lift under certain conditions.  This calculation inherently relies on the number Pi, and Pi itself is an irrational number (in fact, a transcendental number) - that is, it has infinitely non-repeating decimal places.  This means that your calculation of the curvature of the wing will only ever be solved to as many significant digits as you have used in your implementation of Pi in the equation.&lt;/p&gt;

&lt;p&gt;And that is only a consideration on a mathematical level.  A similar degree of uncertainty arises on a computational level.  Hopefully you're using a computer to do these calculations, but you're computer itself has an inherent degree of granularity hard-coded within its ability to perform calculations.  This includes the fact that there is a limited set of numbers your computer can use constrained by the number of possible bits allocated for a number type (I may be fudging some terms here - but the message is there).  This also includes how your computer traverses a continuous set - say, the number line between 0 and 1.  Ultimately, there's a discreteness introduced into what is otherwise a supposed continuous process due to the fact that there is a limited set of numbers a computer has available to itself.&lt;/p&gt;

&lt;p&gt;Uncertainty in this form is so prevalent in all fields in the physical sciences that there are whole disciplines and numerous methods devoted specifically to address the problem.  Disciplines like Numerical Analysis and methods such as Perturbation Theory are are, by design, meant to expedite approximations so that they can be computed faster and with more certainty (numerical analysis) - and, in fact, to give us at least some approach to solving for something that cannot be exactly solved for (perturbative methods).&lt;/p&gt;

&lt;p&gt;I now want to revisit the concept of mathematical uncertainty that I touched upon earlier.  If you were to draw a line segment and label one end 0 and the other end 100, and you were then to, say, throw a dart which hits a point on said line.  You have a 0% chance of hitting a whole number.  In fact you have a 0% chance of hitting even a rational number.  MOREOVER, you have a 0% chance of hitting even an algebraic number (algebraic numbers encompass even irrational numbers such as the square root of 2 because it can be written as the solution to an algebraic equation - that is x^2 = 2).&lt;/p&gt;

&lt;p&gt;The set of whole numbers, rational numbers, and algebraic numbers has a size of infinity.  The size of the set of all real numbers also has a size of infinity.  But the size of the set or real numbers is, in a sense, so much more infinite than the size of whole/rational numbers (google 'continuum hypothesis').  The point is, just as how almost all equations cannot be solved for exactly, the same is true of numbers.  'Almost All' (this is a true mathematical condition, almost all, wiki it) numbers are transcendental.  They cannot be expressed as the solution to some finite equation.  They cannot be computed to infinite precision within finite time.  And this is not a physical concept we are referring to.  We are referring to the concept of numbers!  We are referring to something that exists only in the mind!  Yet even that cannot be determined to infinite precision.&lt;/p&gt;

&lt;p&gt;The uneasiness about this idea was contemplated as far back as the ancient Greeks (probably even farther).  The discovery of irrational numbers is usually attributed to Hippasus, who belonged to a group called the Pythagoreans.  The Pythagoreans were a sect who followed the teachings of Pythagoras influenced mostly via a study of astronomy, mathematics, and music.  It is said that when Hippasus brought to light his discovery of irrational numbers at sea, his fellow compatriots threw him overboard "...for having produced an element in the universe which denied the...doctrine that all phenomena in the universe can be reduced to whole numbers and their ratios."&lt;/p&gt;

&lt;p&gt;If you've made it this far, congratulations, you've basically just had me fart into your ears for the last 5 minutes.  I'd like to say more, but this can go on forever (maybe in another blog post).  Cherish the moments you have, cherish the ones you love, cherish the time you spend with one another.  Their fate is as uncertain as your own.  The only thing certain, is uncertainty itself - the only constant, is change itself.  And now I go back to coding.  As always - stay happy, stay strong, stay passionate - and take care of yourselves.&lt;/p&gt;</content:encoded></item><item><title>MakerSquare vs US Model of Education</title><description>&lt;p&gt;So I've just started my program at MakerSquare, one and a half weeks in, and it has already been one of the best experience of my life.  MakerSquare is a "Tech Bootcamp", a class that seeks to teach you the fundamentals of some form of programming (generally web-related) within the&lt;/p&gt;</description><link>http://localhost:2368/makersquare-vs-u-s-model-of-education/</link><guid isPermaLink="false">2b5914c3-d026-458b-9d1d-e9e24a8b38c0</guid><dc:creator>Jeffrey Yang</dc:creator><pubDate>Thu, 15 Oct 2015 14:33:18 GMT</pubDate><content:encoded>&lt;p&gt;So I've just started my program at MakerSquare, one and a half weeks in, and it has already been one of the best experience of my life.  MakerSquare is a "Tech Bootcamp", a class that seeks to teach you the fundamentals of some form of programming (generally web-related) within the span of a few months such that you can apply for a job in said field right after you graduate.&lt;/p&gt;

&lt;p&gt;Tech bootcamp programs tend to last roughly 3-4 months and the issue they seek to address is to produce truly useful individuals for the real world in software engineering upon graduation.  The reason this is even an issue is because most colleges/universities teach "Computer Science" (a.k.a. CS) but they do not have a program for "Software Engineering". They teach the theoretical framework of programming but they do not emphasize the applicability.  It's like teaching music theory, but never encouraging/training students to compose songs. And then sending students out into the field who may have a solid understanding of theory, but no idea how to compose.&lt;/p&gt;

&lt;p&gt;Face it, you are going to encounter challenges along the way when you are trying to create something new from scratch. And that is where colleges fail and "Trade Schools" succeed - that is what MakerSquare is, a trade school. You are learning one skill - software engineering in this case, and the entire course is focused on achieving proficiency and real-world applicability in this one skill. And this is where I will now segue into my critique of the educational model of the US.&lt;/p&gt;

&lt;p&gt;I am enjoying MakerSquare so much right now because, never have I been in an environment where everyone wants to be here. And by everyone, I mean students, instructors, and staff.  Students are all required to be within the premises 11 hours a day Mon-Fri and 8 and a half hours on Sat. It's called a bootcamp for a reason. Think about standard schools elementary through college - 75-90% of the students hate it and are only there because their parents force them or because it's what they feel is expected of them via social pressure.&lt;/p&gt;

&lt;p&gt;But the real amazing thing about MakerSquare is, everyone WANTS to be here. The vibe is insane. Students, Staff, and Instructors regularly stay 12+ hours because they WANT to be here - they WANT to learn, they WANT to facilitate, they WANT to teach (respectively).&lt;/p&gt;

&lt;p&gt;I have been an instructor for as many as 15 students at a time (taught courses in SAT math, AP calculus, AP physics, etc.) and I've been a student (obviously). I've seen both sides of the spectrum and MakerSquare is unique because this is the first time I've been in a class where EVERYONE wants to be here and EVERYONE wants to try their best.&lt;/p&gt;

&lt;p&gt;Which leads me to my next point - that the US's model of education is extremely outdated. Throughout history, the most successful individuals (in terms of their contribution/improvement to society as a whole) made their most influential discoveries between the ages of 16-25.&lt;/p&gt;

&lt;p&gt;And, yet, in the U.S. educational model, we expect/enforce our citizens to - finish high school -&gt; go to college -&gt; ??? - &gt; profit (get job).  Basically, we take people at the prime of their lives, and place them into an institution where they sit on their asses and listen to some dude lecture, and then they go home and recite the lecture on paper (homework). Like, what is the point?  This is the time when one should get their hands dirty, to have some real hands-on experience, and yet they are just taking rote memorization classes. Even worse, half or more of the classes are GE's (general education) and are completely unrelated to the major one chose when he/she applied for said college.&lt;/p&gt;

&lt;p&gt;Consider the educational model of the progressive countries in the EU (European Union). In countries like Germany, Denmark, and the Netherlands - they actually discourage students from attending university. Not only that, their high school ends at grade 10 or 11 wherein students either go directly into the work force, take part in some form of apprenticeship, or attend a trade school (see where I'm getting at). &lt;/p&gt;

&lt;p&gt;These progressive countries in the EU realize that a person should only enroll in university if he/she truly wants to work in academia and research.  University is essentially a trade school for becoming either a researcher or professor (usually both). Off topic tangent - I do not know what it's like in the countries I'm promoting, but it's hilarious that most universities in America require their researchers to teach courses.  It's stupid because some people are amazing at research but terrible at teaching, maybe because they are just inherently bad at it, but mostly because they just don't care much for it. So now you just have some dude/dudette giving a half-assed lecture because he/she just wants to get back to his/her actual job - researching. And this negative feedback of a brilliant researcher giving a crap lecture goes on to instill a lack of interest in the students attending said lecture.&lt;/p&gt;

&lt;p&gt;One final thought. I had a friend bring up an interesting point when I discussed this viewpoint of mine. That the countries in the EU adopt a rather Socialist system whereas the US is obviously Capitalist. His opinion is that there is less chance to "make it big" in the EU than in the US. But having thought more about it, I am still very much against the US's educational model/policies. I've just bagged on how American universities force their researchers to teach whether they want to or not. But consider our lower level educators.&lt;/p&gt;

&lt;p&gt;If you're an American, you must by now have realized that the profession of teaching (from elementary through high school) in the US is extremely looked down upon. And why is that? We look down on the people who are the ones in charge of educating the next generation so we can improve ourselves as a species. It's ludicrous. In the progressive countries in the EU, teaching is a highly respected profession and teachers are paid extremely well so people who are geared towards being and educator are incentivized to go into the field.  But in the US, we scoff and laugh at our educators as the 'dumb ones' who couldn't get a job in some field and instead had to teach 'uneducated children'.  Once again, a negative feedback loop that just makes things worse and worse.  Low pay and lack of respect means the people who become teachers in the US tend, to be frank, to suck a lot. &lt;/p&gt;

&lt;p&gt;To reinforce this point, I was a physics major in university in the US, and there were several tracks you could take - BioPhysics, Mathematical Physics, AstroPhysics, and finally Physics Education - that is, becoming a physics/science teacher for schools below the college level. And the lowest caliber students ended up doing the Physics Education track because it was the easiest.  So basically, the worst students took up the role of being the ones to teach the next generation of students...think about that...&lt;/p&gt;

&lt;p&gt;Anyway, I've gone on for a bit too long - back to MakerSquare and coding until my brain won't work anymore. Stay strong, stay happy, stay passionate - and take care of yourselves.&lt;/p&gt;</content:encoded></item></channel></rss>